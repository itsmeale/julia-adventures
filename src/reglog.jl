module RegLog


include("metrics.jl")

using CSV, DataFrames, LinearAlgebra, Plots, .Metrics

export logisticregression

#=
Codifica a variavel alvo multiclasse para um vetor de dimensÃ£o
K onde, K Ã© o nÃºmero de classes.

Se o conjunto de classes Ã© {1, 2, 3}, uma instÃ¢ncia pode ser
codificada como [1, 0, 0], [0, 1, 0] ou [0, 0, 1].
=#
function preparey(y::Vector)::Matrix
    n = size(y)[1]
    Y = zeros(n, 3)
    ð“’ = unique(y)
    for (idx, class) âˆˆ enumerate(y)
        classindex = findfirst(c -> c == class, ð“’)
        Y[idx, classindex] = 1
    end
    return Y
end

#= Le o dataset iris =#
function readiris()
    path = "data/raw/iris.m"
    df = DataFrame(CSV.File(path, header=false))
    X = Matrix(df[:, 1:4])
    Y = Vector(df[:, 5])
    return X, Y
end

function softmax(ð“¢)
    k = size(ð“¢)[2]
    return exp.(ð“¢) ./ (sum(exp.(ð“¢), dims=2) * ones(1, k))
end

function logisticregression(X, Y)

    X, Y = readiris()
    Yâ‚˜ = preparey(Y)
    n, ð““ = size(X)  # number of instances and features
    k = size(Yâ‚˜)[2]  # number of classes

    # auxiliar functions
    total_error(Y, YÌ‚) = -sum(Y .* log.(YÌ‚))
    ð›g(E, X) = E' * X

    # add bias and create weights vector
    X = hcat(X, ones(n))
    ð“¦ = rand(k, ð““ + 1)

    it = 0
    itmax = 1000
    Î· = 1e-3
    Ïµ = 1e-3
    errors = Vector{Float64}()
    grad_norm = Inf

    while (grad_norm > Ïµ) & (it < itmax)
        ð“¢ = X * ð“¦'
        YÌ‚ = softmax(ð“¢)
        ð› = ð›g(YÌ‚ - Yâ‚˜, X)
        ð“¦ -= Î· * ð›
        ð“” = total_error(Yâ‚˜, YÌ‚)
        grad_norm = norm(ð›)

        println("it $it, E=$ð“”")
        push!(errors, ð“”)
        it += 1
    end

    # evaluation metrics
    Metrics.multiclass_report(Yâ‚˜, YÌ‚)
    plot(errors)

    return YÌ‚, ð“¦, errors
end


end